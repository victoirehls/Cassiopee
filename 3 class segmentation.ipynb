{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5edc93da-bd62-46bb-ba16-3d54a9656cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3e1fe2-71e2-4d5d-ad46-03c1a320ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85611af1-ccd9-4a0f-9564-c68e05a29e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1015f9-72c8-4f99-88d2-122ac8de1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bacde84-a9a0-4ee7-b093-6113ab440536",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b960f51-8e22-4277-958b-e34bd3f8c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0584f620-4822-444b-afe4-ec9484d454d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = [1,1]\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        sd.append(step_decay(len(self.losses)))\n",
    "        print('lr:', step_decay(len(self.losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97df265c-4354-4c92-bbbc-782947b29efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e362a465-9ddb-493d-8164-3c9b4e10432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "200bf8fd-7605-4a4f-8a12-a91f38b9fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def step_decay(losses):\n",
    "    if float(2*np.sqrt(np.array(history.losses[-1])))<0.3:\n",
    "        lrate=0.01*1/(1+0.1*len(history.losses))\n",
    "        momentum=0.8\n",
    "        decay_rate=2e-6\n",
    "        return lrate\n",
    "    else:\n",
    "        lrate=0.1\n",
    "        return lrate\n",
    "lrate=LearningRateScheduler(step_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76315a72-2cfb-4068-8a58-096de4a3d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f76c63-cea5-4de7-b003-6b514e42e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "log_dir=\"/space/storage/homes/vrv/cellseg-cuda/victor/logs/\"\n",
    "tensorboard_callback= tf.keras.callbacks.TensorBoard(log_dir=log_dir,                     \n",
    "                               histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18996e2d-ad9c-4371-8ab5-3669ae6821ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model/3_class_50ep_after_new_data_SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "215a3ad2-aa0e-489c-a5eb-f23b4fb72260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /space/storage/homes/vrv/cellseg-cuda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(inputs, filters, pool=True):\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPool2D((2, 2))(x)\n",
    "        return x, p\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def build_unet(shape, num_classes):\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    x1, p1 = conv_block(inputs, 16, pool=True)\n",
    "    x2, p2 = conv_block(p1, 32, pool=True)\n",
    "    x3, p3 = conv_block(p2, 48, pool=True)\n",
    "    x4, p4 = conv_block(p3, 64, pool=True)\n",
    "\n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = conv_block(p4, 128, pool=False)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n",
    "    c1 = Concatenate()([u1, x4])\n",
    "    x5 = conv_block(c1, 64, pool=False)\n",
    "\n",
    "    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n",
    "    c2 = Concatenate()([u2, x3])\n",
    "    x6 = conv_block(c2, 48, pool=False)\n",
    "\n",
    "    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n",
    "    c3 = Concatenate()([u3, x2])\n",
    "    x7 = conv_block(c3, 32, pool=False)\n",
    "\n",
    "    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n",
    "    c4 = Concatenate()([u4, x1])\n",
    "    x8 = conv_block(c4, 16, pool=False)\n",
    "\n",
    "    \"\"\" Output layer \"\"\"\n",
    "    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n",
    "\n",
    "    return Model(inputs, output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_unet((128, 128, 1), 3)\n",
    "    #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4480c08c-f574-4065-94e1-f773dd92b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paths = os.listdir('/space/storage/homes/vrv/cellseg-cuda/processed_data/new_data/originals')\n",
    "y_paths = os.listdir('/space/storage/homes/vrv/cellseg-cuda/processed_data/new_data/labels_3_classes')\n",
    "X_paths.sort()\n",
    "y_paths.sort()\n",
    "nb_img=len(X_paths)\n",
    "img_height=128\n",
    "img_width=128\n",
    "X = np.zeros((nb_img, img_height, img_width,1), dtype=np.uint8)\n",
    "y = np.zeros((nb_img, img_height, img_width,1), dtype=np.uint8)\n",
    "for i in range(len(X_paths)) : \n",
    "    img = imread('/space/storage/homes/vrv/cellseg-cuda/processed_data/new_data/originals/' + X_paths[i])\n",
    "    img = resize(img, (img_height, img_width), mode='constant', preserve_range=True)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    X[i]=img\n",
    "for j in range(len(y_paths)) : \n",
    "    img = imread('/space/storage/homes/vrv/cellseg-cuda/processed_data/new_data/labels_3_classes/' + y_paths[j])\n",
    "    img = resize(img, (img_height, img_width), mode='constant', preserve_range=True)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    y[j]=img\n",
    "n = len(X)\n",
    "r = int(n*0.8)\n",
    "\n",
    "X_train = X[:r]\n",
    "X_test = X[r+1:]\n",
    "\n",
    "y_train = y[:r]\n",
    "y_test = y[r+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb5014-0a0a-4f24-ae2e-cb0b06c13fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d14079-dcb2-41e3-a6ff-cf936660a2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66181 66181\n"
     ]
    }
   ],
   "source": [
    "print(len(X),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ceb7a74-9555-499f-b69b-6a5477d92d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e31b5d3c-6710-43e9-8f36-68c6df0faaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='victor/tbCb3', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e5bb056-9325-44c5-9760-6d6bb7236eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"model/cpNEW_DATA.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea38fd7-2c40-432d-98eb-d78f7ad5f7aa",
   "metadata": {},
   "source": [
    "### CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ac909a-bf68-4a09-bb6c-a08d173dd759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt\n",
    ", loss='sparse_categorical_crossentropy', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eaeaeaa-f412-4e0d-a7a2-233257b849f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "853b5ea9-365c-4900-91fb-10236f8ca39b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47649 samples, validate on 5295 samples\n",
      "Epoch 1/50\n",
      "47632/47649 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9817lr: 0.1\n",
      "47649/47649 [==============================] - 89s 2ms/sample - loss: 0.0443 - acc: 0.9817 - val_loss: 0.0407 - val_acc: 0.9832\n",
      "Epoch 2/50\n",
      "47648/47649 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9825lr: 0.1\n",
      "47649/47649 [==============================] - 89s 2ms/sample - loss: 0.0424 - acc: 0.9825 - val_loss: 0.0360 - val_acc: 0.9851\n",
      "Epoch 3/50\n",
      "47648/47649 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9832lr: 0.1\n",
      "47649/47649 [==============================] - 89s 2ms/sample - loss: 0.0407 - acc: 0.9832 - val_loss: 0.0354 - val_acc: 0.9848\n",
      "Epoch 4/50\n",
      "47632/47649 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9837lr: 0.1\n",
      "47649/47649 [==============================] - 88s 2ms/sample - loss: 0.0396 - acc: 0.9837 - val_loss: 0.0356 - val_acc: 0.9851\n",
      "Epoch 5/50\n",
      "47648/47649 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9842lr: 0.1\n",
      "47649/47649 [==============================] - 88s 2ms/sample - loss: 0.0384 - acc: 0.9842 - val_loss: 0.0445 - val_acc: 0.9820\n",
      "Epoch 6/50\n",
      "12144/47649 [======>.......................] - ETA: 1:03 - loss: 0.0376 - acc: 0.9845"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-be6351f69feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/space/storage/homes/vrv/cellseg-cuda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/space/storage/homes/vrv/cellseg-cuda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/storage/homes/vrv/cellseg-cuda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/space/storage/homes/vrv/cellseg-cuda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.1, batch_size=16, epochs=50, callbacks=[tensorboard_callback, mc, es, history, lrate],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1554b7f0-8fc4-4e87-ab1f-19630aadf939",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/3_class_50ep_after_new_data_adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f02edd37-482d-482a-99a9-20876a323db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "13236/13236 [==============================] - 6s 446us/sample - loss: 0.0488 - acc: 0.9874\n",
      "test loss, test acc: [0.04884987081414841, 0.98736703]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af5b9b-7d5d-4c32-85e8-e71a5686ccf4",
   "metadata": {},
   "source": [
    "### Test sur une image (289 premiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40497386-fc29-4e10-8722-bd5104eb39c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289, 128, 128, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "img_height=128\n",
    "img_width=128\n",
    "dest_originals_path='/space/storage/homes/vrv/cellseg-cuda/processed_data/new_data/originals/'\n",
    "d_o = [f for f in listdir(dest_originals_path) if isfile(join(dest_originals_path, f))]\n",
    "d_o.sort()\n",
    "test_predict=[]\n",
    "for i in range(289) : \n",
    "    img = imread(dest_originals_path + d_o[i])\n",
    "    img = resize(img, (img_height, img_width), mode='constant', preserve_range=True)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    test_predict.append(img)\n",
    "test_predict=np.array(test_predict)\n",
    "test_predict.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
